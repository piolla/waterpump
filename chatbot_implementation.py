import streamlit as st
import json
import pandas as pd
import numpy as np
from datetime import datetime
import plotly.express as px
import plotly.graph_objects as go
import re
from water_pump_analyzer import WaterPumpAnalyzer

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="ì›Œí„°íŒí”„ AI ë¶„ì„ ì±—ë´‡",
    page_icon="ğŸ¤–",
    layout="wide"
)

class WaterPumpChatbot:
    def __init__(self):
        self.data = None
        self.analysis_cache = {}
        
    def load_json_data(self, uploaded_file):
        """JSON ë°ì´í„° ë¡œë“œ"""
        try:
            self.data = json.load(uploaded_file)
            self.analyze_data()
            return True
        except Exception as e:
            st.error(f"ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜: {e}")
            return False
    
    def analyze_data(self):
        """ë°ì´í„° ë¶„ì„ ë° ìºì‹œ ìƒì„±"""
        if not self.data:
            return
            
        results = self.data['analysis_results']
        
        # ì „ì²´ í†µê³„ ê³„ì‚°
        all_temps = []
        alert_counts = {'ì •ìƒ': 0, 'ê´€ì°°': 0, 'ì£¼ì˜': 0, 'ìœ„í—˜': 0}
        trend_counts = {'ìƒìŠ¹': 0, 'í•˜ê°•': 0, 'í‰í˜•': 0}
        stability_counts = {'ë§¤ìš°ì•ˆì •': 0, 'ì•ˆì •': 0, 'ë³´í†µ': 0, 'ë¶ˆì•ˆì •': 0}
        
        critical_batches = []
        
        for result in results:
            all_temps.append(result['statistics']['mean'])
            alert_counts[result['alert_level']] += 1
            trend_counts[result['trend']] += 1
            stability_counts[result['stability']] += 1
            
            # ìœ„í—˜/ì£¼ì˜ ë°°ì¹˜ ì‹ë³„
            if result['alert_level'] in ['ìœ„í—˜', 'ì£¼ì˜']:
                critical_batches.append(result)
        
        self.analysis_cache = {
            'total_batches': len(results),
            'avg_temperature': np.mean(all_temps),
            'max_temperature': max([r['statistics']['max'] for r in results]),
            'min_temperature': min([r['statistics']['min'] for r in results]),
            'alert_counts': alert_counts,
            'trend_counts': trend_counts,
            'stability_counts': stability_counts,
            'critical_batches': critical_batches,
            'analysis_period': {
                'start': results[0]['start_timestamp'],
                'end': results[-1]['end_timestamp']
            }
        }
    
    def get_emergency_alert(self):
        """ê¸´ê¸‰ ìƒí™© ì²´í¬"""
        critical_batches = self.analysis_cache['critical_batches']
        emergency_batches = [b for b in critical_batches if b['alert_level'] == 'ìœ„í—˜']
        
        if emergency_batches:
            return self.format_emergency_response(emergency_batches)
        return None
    
    def format_emergency_response(self, emergency_batches):
        """ê¸´ê¸‰ ìƒí™© ì‘ë‹µ í¬ë§·"""
        response = "ğŸš¨ **ê¸´ê¸‰ ì•Œë¦¼: ì›Œí„°íŒí”„ ê³¼ì—´ ê°ì§€**\n\n"
        
        for batch in emergency_batches:
            response += f"â›” **ìœ„í—˜ ìƒí™© - ë°°ì¹˜ {batch['batch_id']}**\n"
            response += f"- ìµœê³  ì˜¨ë„: {batch['statistics']['max']:.1f}Â°C\n"
            response += f"- í‰ê·  ì˜¨ë„: {batch['statistics']['mean']:.1f}Â°C\n"
            response += f"- ë°œìƒ ì‹œê°„: {batch['start_timestamp']}\n"
            response += f"- ì˜¨ë„ íŠ¹ì„±: {batch['value_label']}\n\n"
        
        response += "ğŸ”§ **ì¦‰ì‹œ ì¡°ì¹˜ì‚¬í•­**\n"
        response += "1. ì›Œí„°íŒí”„ ì¦‰ì‹œ ì •ì§€ ë° ì•ˆì „ ì ê²€\n"
        response += "2. ëƒ‰ê°ìˆ˜ ìœ ëŸ‰ ë° ì˜¨ë„ í™•ì¸\n"
        response += "3. ëƒ‰ê° í•„í„° ë° ë¼ë””ì—ì´í„° ì ê²€\n"
        response += "4. ë² ì–´ë§ ë° ì”° ìƒíƒœ í™•ì¸\n"
        response += "5. í˜„ì¥ ë‹´ë‹¹ì ì¦‰ì‹œ ì—°ë½\n\n"
        
        response += "ğŸ“ **í›„ì† ì¡°ì¹˜**\n"
        response += "- ì •ë¹„íŒ€ ëŒ€ê¸° ìš”ì²­\n"
        response += "- ì›ì¸ ë¶„ì„ í›„ ì¬ê°€ë™ ê²°ì •\n"
        
        return response
    
    def analyze_user_query(self, query):
        """ì‚¬ìš©ì ì§ˆë¬¸ ë¶„ì„ ë° ì‘ë‹µ ìƒì„±"""
        query = query.lower()
        
        # ê¸´ê¸‰ ìƒí™© ìš°ì„  ì²´í¬
        emergency = self.get_emergency_alert()
        if emergency and any(word in query for word in ['ìœ„í—˜', 'ë¬¸ì œ', 'ì´ìƒ', 'ê²½ê³ ', 'ì•Œë¦¼']):
            return emergency
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ì‘ë‹µ ë¶„ê¸°
        if any(word in query for word in ['ì „ì²´', 'ì „ë°˜', 'ê°œìš”', 'ìš”ì•½', 'ìƒí™©']):
            return self.get_overall_analysis()
        elif any(word in query for word in ['ì˜¨ë„', 'í‰ê· ', 'ìµœê³ ', 'ìµœì €']):
            return self.get_temperature_analysis()
        elif any(word in query for word in ['íŠ¸ë Œë“œ', 'ë³€í™”', 'íŒ¨í„´', 'ê²½í–¥']):
            return self.get_trend_analysis()
        elif any(word in query for word in ['ìœ„í—˜', 'ì£¼ì˜', 'ê²½ê³ ', 'ë¬¸ì œ']):
            return self.get_risk_analysis()
        elif any(word in query for word in ['ì˜ˆì¸¡', 'ì •ë¹„', 'ì ê²€', 'ìœ ì§€ë³´ìˆ˜']):
            return self.get_maintenance_advice()
        elif any(word in query for word in ['íš¨ìœ¨', 'ìµœì í™”', 'ê°œì„ ', 'ì„±ëŠ¥']):
            return self.get_optimization_advice()
        else:
            return self.get_general_response(query)
    
    def get_overall_analysis(self):
        """ì „ì²´ ë¶„ì„ ì‘ë‹µ"""
        cache = self.analysis_cache
        
        response = "ğŸ” **ì›Œí„°íŒí”„ ì˜¨ë„ ì „ì²´ ë¶„ì„ ê²°ê³¼**\n\n"
        
        response += "ğŸ“Š **ì „ì²´ í˜„í™©**\n"
        response += f"- ë¶„ì„ ê¸°ê°„: {cache['analysis_period']['start'][:10]} ~ {cache['analysis_period']['end'][:10]}\n"
        response += f"- ì´ ë°°ì¹˜ ìˆ˜: {cache['total_batches']}ê°œ\n"
        response += f"- í‰ê·  ì˜¨ë„: {cache['avg_temperature']:.1f}Â°C\n"
        response += f"- ìµœê³  ì˜¨ë„: {cache['max_temperature']:.1f}Â°C\n"
        response += f"- ìµœì € ì˜¨ë„: {cache['min_temperature']:.1f}Â°C\n\n"
        
        response += "âš ï¸ **ê²½ê³  ìˆ˜ì¤€ ë¶„í¬**\n"
        for level, count in cache['alert_counts'].items():
            percentage = (count / cache['total_batches']) * 100
            response += f"- {level}: {count}ê°œ ({percentage:.1f}%)\n"
        
        response += "\nğŸ“ˆ **ì£¼ìš” ë°œê²¬ì‚¬í•­**\n"
        critical_count = cache['alert_counts']['ìœ„í—˜'] + cache['alert_counts']['ì£¼ì˜']
        if critical_count > 0:
            response += f"- ìœ„í—˜/ì£¼ì˜ ë°°ì¹˜: {critical_count}ê°œ ë°œê²¬\n"
            response += "- ì¦‰ì‹œ ì ê²€ ë° ì¡°ì¹˜ í•„ìš”\n"
        else:
            response += "- ì „ë°˜ì ìœ¼ë¡œ ì•ˆì •ì ì¸ ìš´ì˜ ìƒíƒœ\n"
            
        if cache['avg_temperature'] > 75:
            response += "- í‰ê·  ì˜¨ë„ê°€ ë†’ì€ í¸ìœ¼ë¡œ ëƒ‰ê° íš¨ìœ¨ ì ê²€ ê¶Œì¥\n"
        
        return response
    
    def get_temperature_analysis(self):
        """ì˜¨ë„ ë¶„ì„ ì‘ë‹µ"""
        cache = self.analysis_cache
        results = self.data['analysis_results']
        
        response = "ğŸŒ¡ï¸ **ì˜¨ë„ ìƒì„¸ ë¶„ì„**\n\n"
        
        # ì˜¨ë„ ë²”ìœ„ë³„ ë¶„í¬
        temp_ranges = {'ì €ì˜¨ (<40Â°C)': 0, 'ì •ìƒ (40-70Â°C)': 0, 'ê³ ì˜¨ (70-85Â°C)': 0, 'ê³¼ì—´ (>85Â°C)': 0}
        
        for result in results:
            mean_temp = result['statistics']['mean']
            if mean_temp < 40:
                temp_ranges['ì €ì˜¨ (<40Â°C)'] += 1
            elif mean_temp < 70:
                temp_ranges['ì •ìƒ (40-70Â°C)'] += 1
            elif mean_temp < 85:
                temp_ranges['ê³ ì˜¨ (70-85Â°C)'] += 1
            else:
                temp_ranges['ê³¼ì—´ (>85Â°C)'] += 1
        
        response += "ğŸ“Š **ì˜¨ë„ ë²”ìœ„ë³„ ë¶„í¬**\n"
        for range_name, count in temp_ranges.items():
            percentage = (count / cache['total_batches']) * 100
            response += f"- {range_name}: {count}ê°œ ({percentage:.1f}%)\n"
        
        response += f"\nğŸ”¥ **ì˜¨ë„ í†µê³„**\n"
        response += f"- ì „ì²´ í‰ê· : {cache['avg_temperature']:.1f}Â°C\n"
        response += f"- ìµœê³  ê¸°ë¡: {cache['max_temperature']:.1f}Â°C\n"
        response += f"- ìµœì € ê¸°ë¡: {cache['min_temperature']:.1f}Â°C\n"
        
        # ê³ ì˜¨ ë°°ì¹˜ ì‹ë³„
        high_temp_batches = [r for r in results if r['statistics']['mean'] > 80]
        if high_temp_batches:
            response += f"\nâš ï¸ **ê³ ì˜¨ ë°°ì¹˜ ({len(high_temp_batches)}ê°œ)**\n"
            for batch in high_temp_batches[:3]:  # ìƒìœ„ 3ê°œë§Œ í‘œì‹œ
                response += f"- ë°°ì¹˜ {batch['batch_id']}: {batch['statistics']['mean']:.1f}Â°C ({batch['value_label']})\n"
        
        return response
    
    def get_trend_analysis(self):
        """íŠ¸ë Œë“œ ë¶„ì„ ì‘ë‹µ"""
        cache = self.analysis_cache
        
        response = "ğŸ“ˆ **ì˜¨ë„ íŠ¸ë Œë“œ ë¶„ì„**\n\n"
        
        response += "ğŸ“Š **íŠ¸ë Œë“œ ë¶„í¬**\n"
        for trend, count in cache['trend_counts'].items():
            percentage = (count / cache['total_batches']) * 100
            response += f"- {trend} íŠ¸ë Œë“œ: {count}ê°œ ({percentage:.1f}%)\n"
        
        response += "\nğŸ”„ **ì•ˆì •ì„± ë¶„í¬**\n"
        for stability, count in cache['stability_counts'].items():
            percentage = (count / cache['total_batches']) * 100
            response += f"- {stability}: {count}ê°œ ({percentage:.1f}%)\n"
        
        # íŠ¸ë Œë“œ í•´ì„
        response += "\nğŸ’¡ **íŠ¸ë Œë“œ í•´ì„**\n"
        if cache['trend_counts']['ìƒìŠ¹'] > cache['total_batches'] * 0.3:
            response += "- ì˜¨ë„ ìƒìŠ¹ íŠ¸ë Œë“œê°€ ìš°ì„¸í•¨ â†’ ëƒ‰ê° ì‹œìŠ¤í…œ ì ê²€ í•„ìš”\n"
        if cache['stability_counts']['ë¶ˆì•ˆì •'] > cache['total_batches'] * 0.2:
            response += "- ì˜¨ë„ ë³€ë™ì´ í° ë°°ì¹˜ê°€ ë§ìŒ â†’ ìš´ì˜ ì¡°ê±´ ì ê²€ í•„ìš”\n"
        if cache['trend_counts']['í‰í˜•'] > cache['total_batches'] * 0.6:
            response += "- ëŒ€ë¶€ë¶„ ì•ˆì •ì ì¸ ì˜¨ë„ ìœ ì§€ â†’ ì–‘í˜¸í•œ ìš´ì˜ ìƒíƒœ\n"
        
        return response
    
    def get_risk_analysis(self):
        """ìœ„í—˜ ë¶„ì„ ì‘ë‹µ"""
        cache = self.analysis_cache
        critical_batches = cache['critical_batches']
        
        response = "âš ï¸ **ìœ„í—˜ ìš”ì†Œ ë¶„ì„**\n\n"
        
        if not critical_batches:
            response += "âœ… **ì–‘í˜¸í•œ ìƒíƒœ**\n"
            response += "- í˜„ì¬ ìœ„í—˜ ë˜ëŠ” ì£¼ì˜ ë°°ì¹˜ ì—†ìŒ\n"
            response += "- ì •ìƒì ì¸ ìš´ì˜ ë²”ìœ„ ë‚´ì—ì„œ ë™ì‘\n"
            return response
        
        response += f"ğŸš¨ **ìœ„í—˜/ì£¼ì˜ ë°°ì¹˜: {len(critical_batches)}ê°œ**\n\n"
        
        for batch in critical_batches:
            response += f"**ë°°ì¹˜ {batch['batch_id']} ({batch['alert_level']})**\n"
            response += f"- í‰ê·  ì˜¨ë„: {batch['statistics']['mean']:.1f}Â°C\n"
            response += f"- ìµœê³  ì˜¨ë„: {batch['statistics']['max']:.1f}Â°C\n"
            response += f"- íŠ¹ì„±: {batch['value_label']}\n"
            response += f"- ë°œìƒ ì‹œê°„: {batch['start_timestamp'][:16]}\n\n"
        
        response += "ğŸ”§ **ê¶Œì¥ ì¡°ì¹˜ì‚¬í•­**\n"
        response += "1. ê³ ì˜¨ ë°°ì¹˜ ì›ì¸ ë¶„ì„ (ë¶€í•˜, ëƒ‰ê°ìˆ˜, í™˜ê²½ì˜¨ë„)\n"
        response += "2. ëƒ‰ê° ì‹œìŠ¤í…œ ì ê²€ (í•„í„°, íŒí”„, ë¼ë””ì—ì´í„°)\n"
        response += "3. ë² ì–´ë§ ë° íšŒì „ë¶€ ìœ¤í™œ ìƒíƒœ í™•ì¸\n"
        response += "4. ì˜¨ë„ ì„¼ì„œ ì •í™•ë„ ê²€ì¦\n"
        
        return response
    
    def get_maintenance_advice(self):
        """ì •ë¹„ ì¡°ì–¸ ì‘ë‹µ"""
        cache = self.analysis_cache
        
        response = "ğŸ”§ **ì˜ˆì¸¡ ì •ë¹„ ì¡°ì–¸**\n\n"
        
        # ì •ë¹„ ìš°ì„ ìˆœìœ„ ê²°ì •
        high_temp_ratio = (cache['alert_counts']['ìœ„í—˜'] + cache['alert_counts']['ì£¼ì˜']) / cache['total_batches']
        unstable_ratio = cache['stability_counts']['ë¶ˆì•ˆì •'] / cache['total_batches']
        
        response += "ğŸ“‹ **ì •ë¹„ ìš°ì„ ìˆœìœ„**\n"
        
        if high_temp_ratio > 0.2:
            response += "ğŸ”´ **1ìˆœìœ„: ëƒ‰ê° ì‹œìŠ¤í…œ ì „ë©´ ì ê²€**\n"
            response += "- ëƒ‰ê°ìˆ˜ êµì²´ ë° ìˆœí™˜ ì ê²€\n"
            response += "- ë¼ë””ì—ì´í„° ì²­ì†Œ ë° íŒ¬ ë™ì‘ í™•ì¸\n"
            response += "- ì¨ëª¨ìŠ¤íƒ¯ êµì²´ ê²€í† \n\n"
        
        if unstable_ratio > 0.3:
            response += "ğŸŸ¡ **2ìˆœìœ„: ê¸°ê³„ì  ë¶€í’ˆ ì ê²€**\n"
            response += "- ë² ì–´ë§ ìœ¤í™œ ë° êµì²´\n"
            response += "- ì¶• ì •ë ¬ ìƒíƒœ í™•ì¸\n"
            response += "- ì„í ëŸ¬ ê· í˜• ì ê²€\n\n"
        
        response += "ğŸŸ¢ **3ìˆœìœ„: ì˜ˆë°© ì •ë¹„**\n"
        response += "- ì •ê¸° ì˜¤ì¼ êµì²´\n"
        response += "- ì”° ë° ê°€ìŠ¤ì¼“ ì ê²€\n"
        response += "- ì „ê¸° ì—°ê²°ë¶€ ì ê²€\n\n"
        
        # ì •ë¹„ ì£¼ê¸° ì œì•ˆ
        response += "â° **ê¶Œì¥ ì •ë¹„ ì£¼ê¸°**\n"
        if cache['avg_temperature'] > 75:
            response += "- ë‹¨ê¸° ì ê²€: 1ì£¼ì¼ í›„\n"
            response += "- ì •ê¸° ì •ë¹„: 1ê°œì›” ë‹¨ì¶•\n"
        else:
            response += "- ì •ê¸° ì ê²€: 2ì£¼ í›„\n"
            response += "- ì •ê¸° ì •ë¹„: ê¸°ì¡´ ì£¼ê¸° ìœ ì§€\n"
        
        return response
    
    def get_optimization_advice(self):
        """ìµœì í™” ì¡°ì–¸ ì‘ë‹µ"""
        cache = self.analysis_cache
        
        response = "ğŸ’¡ **ìš´ì˜ ìµœì í™” ì œì•ˆ**\n\n"
        
        response += "âš¡ **ì—ë„ˆì§€ íš¨ìœ¨ì„± ê°œì„ **\n"
        if cache['avg_temperature'] > 70:
            response += "- ëƒ‰ê° íš¨ìœ¨ í–¥ìƒìœ¼ë¡œ ì—ë„ˆì§€ ì ˆì•½ ê°€ëŠ¥\n"
            response += "- ë³€ì† ì œì–´ë¥¼ í†µí•œ ë¶€í•˜ ìµœì í™”\n"
        
        response += "- ìš´ì „ ì‹œê°„ ìµœì í™” (í”¼í¬ ì‹œê°„ëŒ€ íšŒí”¼)\n"
        response += "- ì˜ˆì—´ ì‹œê°„ ë‹¨ì¶• ë°©ì•ˆ\n\n"
        
        response += "ğŸ¯ **ì˜¨ë„ ì œì–´ ì „ëµ**\n"
        response += "- ëª©í‘œ ì˜¨ë„: 50-65Â°C ë²”ìœ„ ìœ ì§€\n"
        response += "- ëƒ‰ê°ìˆ˜ ì˜¨ë„ ìë™ ì œì–´ ì‹œìŠ¤í…œ ë„ì…\n"
        response += "- í™˜ê²½ ì˜¨ë„ ë³´ìƒ ì œì–´\n\n"
        
        response += "ğŸ“Š **ëª¨ë‹ˆí„°ë§ ì²´ê³„ ê°•í™”**\n"
        response += "- ì‹¤ì‹œê°„ ì˜¨ë„ ì•Œë¦¼ ì‹œìŠ¤í…œ\n"
        response += "- íŠ¸ë Œë“œ ê¸°ë°˜ ì˜ˆì¸¡ ì•Œê³ ë¦¬ì¦˜\n"
        response += "- ë‹¤ì¤‘ ì„¼ì„œë¥¼ í†µí•œ ì •í™•ë„ í–¥ìƒ\n"
        
        return response
    
    def get_general_response(self, query):
        """ì¼ë°˜ì ì¸ ì‘ë‹µ"""
        return f"""ğŸ¤– **ì›Œí„°íŒí”„ AI ì–´ì‹œìŠ¤í„´íŠ¸**

ì§ˆë¬¸ì„ ì´í•´í–ˆìŠµë‹ˆë‹¤: "{query}"

ë‹¤ìŒê³¼ ê°™ì€ ë¶„ì„ì„ ë„ì™€ë“œë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

ğŸ“Š **ë¶„ì„ ìœ í˜•**
- "ì „ì²´ ìƒí™©ì€ ì–´ë–¤ê°€ìš”?" - ì „ë°˜ì ì¸ ì˜¨ë„ ë¶„ì„
- "ì˜¨ë„ íŠ¸ë Œë“œ ë¶„ì„í•´ì£¼ì„¸ìš”" - ë³€í™” íŒ¨í„´ ë¶„ì„  
- "ìœ„í—˜ ìš”ì†Œê°€ ìˆë‚˜ìš”?" - ìœ„í—˜ ìƒí™© ì ê²€
- "ì •ë¹„ ê³„íšì„ ì„¸ì›Œì£¼ì„¸ìš”" - ì˜ˆì¸¡ ì •ë¹„ ì¡°ì–¸
- "íš¨ìœ¨ì„± ê°œì„  ë°©ì•ˆì€?" - ìµœì í™” ì œì•ˆ

êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ í•´ì£¼ì‹œë©´ ë” ì •í™•í•œ ë¶„ì„ì„ ì œê³µí•˜ê² ìŠµë‹ˆë‹¤!"""

def load_and_analyze_csv(uploaded_file):
    """CSV íŒŒì¼ ë¡œë“œ ë° ë¶„ì„"""
    try:
        # CSV ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
        preview_df = pd.read_csv(uploaded_file)
        st.sidebar.write("ğŸ“‹ **íŒŒì¼ ë¯¸ë¦¬ë³´ê¸°**")
        st.sidebar.dataframe(preview_df.head(3))
        
        # íŒŒì¼ í¬ì¸í„° ë¦¬ì…‹
        uploaded_file.seek(0)
        
        # ë¶„ì„ê¸° ìƒì„± ë° ë°ì´í„° ë¡œë“œ
        analyzer = WaterPumpAnalyzer()
        
        if analyzer.load_data(uploaded_file=uploaded_file):
            st.sidebar.write(f"ğŸ“Š **ë°ì´í„° ì •ë³´**")
            st.sidebar.write(f"ë ˆì½”ë“œ ìˆ˜: {len(analyzer.data)}")
            st.sidebar.write(f"ì˜¨ë„ ë²”ìœ„: {analyzer.data['value'].min():.1f}Â°C ~ {analyzer.data['value'].max():.1f}Â°C")
            
            # ì˜¨ë„ ë¶„ì„ ì‹¤í–‰
            analyzer.analyze_temperature_characteristics()
            
            # ì±—ë´‡ìš© ë°ì´í„° í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            chatbot_data = {
                'metadata': {
                    'analysis_date': datetime.now().isoformat(),
                    'total_batches': len(analyzer.analyzed_data),
                    'window_size': 100,
                    'data_source': 'uploaded_csv_file'
                },
                'analysis_results': analyzer.analyzed_data
            }
            
            # ì±—ë´‡ì— ë°ì´í„° ì„¤ì •
            st.session_state.chatbot.data = chatbot_data
            st.session_state.chatbot.analyze_data()
            
            # ìë™ìœ¼ë¡œ water_pump_data í´ë”ì— ì €ì¥
            import os
            data_folder = 'water_pump_data'
            if not os.path.exists(data_folder):
                os.makedirs(data_folder)
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            json_filename = f"chatbot_analysis_{timestamp}.json"
            json_path = os.path.join(data_folder, json_filename)
            
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(chatbot_data, f, ensure_ascii=False, indent=2)
            
            st.sidebar.info(f"ğŸ“ ë¶„ì„ ê²°ê³¼ê°€ {json_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            return True
        else:
            st.sidebar.error("âŒ CSV íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨")
            return False
            
    except Exception as e:
        st.sidebar.error(f"âŒ CSV ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        return False

def create_sample_data_for_chatbot():
    """ì±—ë´‡ìš© ìƒ˜í”Œ ë°ì´í„° ìƒì„±"""
    try:
        # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
        sample_data = []
        base_time = datetime.now()
        
        for i in range(500):
            timestamp = base_time + pd.Timedelta(minutes=i*10)
            if i < 100:
                temp = 45 + np.random.normal(0, 2)
            elif i < 200:
                temp = 60 + np.random.normal(0, 3)
            elif i < 300:
                temp = 75 + np.random.normal(0, 5)
            elif i < 400:
                temp = 85 + np.random.normal(0, 4)
            else:
                temp = 50 + np.random.normal(0, 2)
            
            sample_data.append({
                'timestamp': timestamp,
                'value': max(20, min(100, temp))
            })
        
        analyzer = WaterPumpAnalyzer()
        analyzer.load_data(data=sample_data)
        analyzer.analyze_temperature_characteristics()
        
        # ì±—ë´‡ìš© ë°ì´í„° í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        chatbot_data = {
            'metadata': {
                'analysis_date': datetime.now().isoformat(),
                'total_batches': len(analyzer.analyzed_data),
                'window_size': 100,
                'data_source': 'sample_data'
            },
            'analysis_results': analyzer.analyzed_data
        }
        
        # ì±—ë´‡ì— ë°ì´í„° ì„¤ì •
        st.session_state.chatbot.data = chatbot_data
        st.session_state.chatbot.analyze_data()
        
        # ìë™ìœ¼ë¡œ water_pump_data í´ë”ì— ì €ì¥
        import os
        data_folder = 'water_pump_data'
        if not os.path.exists(data_folder):
            os.makedirs(data_folder)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        json_filename = f"sample_data_analysis_{timestamp}.json"
        json_path = os.path.join(data_folder, json_filename)
        
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(chatbot_data, f, ensure_ascii=False, indent=2)
        
        st.sidebar.info(f"ğŸ“ ìƒ˜í”Œ ë°ì´í„° ë¶„ì„ ê²°ê³¼ê°€ {json_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
    except Exception as e:
        st.sidebar.error(f"âŒ ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì‹¤íŒ¨: {e}")

def display_upload_guide():
    """ë°ì´í„° ì—…ë¡œë“œ ê°€ì´ë“œ í‘œì‹œ"""
    st.info("ğŸ“¤ ì‚¬ì´ë“œë°”ì—ì„œ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")
    
    st.header("ğŸ“ ì§€ì›í•˜ëŠ” ë°ì´í„° í˜•ì‹")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("ğŸ“Š CSV íŒŒì¼ í˜•ì‹")
        st.code("""
timestamp,value
2024-01-01 10:00:00,45.2
2024-01-01 10:10:00,46.1
2024-01-01 10:20:00,47.3
2024-01-01 10:30:00,48.0
...
        """, language="csv")
        
        st.success("âœ… **CSV íŒŒì¼ ì¥ì :**\n"
                  "- ì›ì‹œ ë°ì´í„° ì§ì ‘ ì—…ë¡œë“œ\n"
                  "- ì‹¤ì‹œê°„ ë¶„ì„ ì‹¤í–‰\n"
                  "- ìë™ ì „ì²˜ë¦¬ ë° ë¼ë²¨ë§")
    
    with col2:
        st.subheader("ğŸ“„ JSON íŒŒì¼ í˜•ì‹")
        st.code("""
{
  "metadata": {
    "analysis_date": "2024-01-01T10:00:00",
    "total_batches": 5,
    "window_size": 100
  },
  "analysis_results": [...]
}
        """, language="json")
        
        st.info("â„¹ï¸ **JSON íŒŒì¼ íŠ¹ì§•:**\n"
               "- ì´ë¯¸ ë¶„ì„ëœ ë°ì´í„°\n"
               "- ë¹ ë¥¸ ë¡œë“œ ë° ì‹œê°í™”\n"
               "- ê¸°ì¡´ ë¶„ì„ ê²°ê³¼ ì¬í™œìš©")
    
    st.header("ğŸ”§ ìë™ ê¸°ëŠ¥")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        **ğŸ” ì»¬ëŸ¼ ìë™ ë§¤í•‘**
        - timestamp â†” time, date, ì‹œê°„
        - value â†” temp, temperature, ì˜¨ë„
        """)
    
    with col2:
        st.markdown("""
        **ğŸ“Š ìë™ ë¶„ì„**
        - 100ê°œ ë ˆì½”ë“œ ë‹¨ìœ„ ë¶„ì„
        - ì˜¨ë„ íŠ¹ì„± ë¼ë²¨ ìƒì„±
        - ìœ„í—˜ ìˆ˜ì¤€ ìë™ ë¶„ë¥˜
        """)
    
    with col3:
        st.markdown("""
        **âš¡ ì‹¤ì‹œê°„ ëŒ€ì‘**
        - ê³¼ì—´ ìƒí™© ì¦‰ì‹œ ê°ì§€
        - ì˜ˆì¸¡ ì •ë¹„ ì¡°ì–¸
        - ë§ì¶¤í˜• ë¶„ì„ ë¦¬í¬íŠ¸
        """)

def main():
    st.title("ğŸ¤– ì›Œí„°íŒí”„ AI ë¶„ì„ ì±—ë´‡")
    st.markdown("### ì›Œí„°íŒí”„ ì˜¨ë„ ë°ì´í„° ì „ë¬¸ ë¶„ì„ ì–´ì‹œìŠ¤í„´íŠ¸")
    
    # ì±—ë´‡ ì´ˆê¸°í™”
    if 'chatbot' not in st.session_state:
        st.session_state.chatbot = WaterPumpChatbot()
    
    if 'data_loaded' not in st.session_state:
        st.session_state.data_loaded = False
    
    # ì‚¬ì´ë“œë°” - ë°ì´í„° ì—…ë¡œë“œ
    with st.sidebar:
        st.header("ğŸ“‚ ë°ì´í„° ì—…ë¡œë“œ")
        
        # ì—…ë¡œë“œ ë°©ì‹ ì„ íƒ
        upload_method = st.radio(
            "ë°ì´í„° ì…ë ¥ ë°©ì‹:",
            ["CSV íŒŒì¼", "JSON íŒŒì¼", "ìƒ˜í”Œ ë°ì´í„°"]
        )
        
        if upload_method == "CSV íŒŒì¼":
            uploaded_file = st.file_uploader(
                "CSV íŒŒì¼ì„ ë“œë˜ê·¸í•˜ê±°ë‚˜ ì„ íƒí•˜ì„¸ìš”",
                type=['csv'],
                help="timestamp, value ì»¬ëŸ¼ì´ í¬í•¨ëœ CSV íŒŒì¼"
            )
            
            if uploaded_file and not st.session_state.data_loaded:
                if st.button("ğŸ”„ CSV ë¶„ì„ ì‹¤í–‰"):
                    with st.spinner("CSV ë°ì´í„° ë¶„ì„ ì¤‘..."):
                        success = load_and_analyze_csv(uploaded_file)
                        if success:
                            st.session_state.data_loaded = True
                            st.success("âœ… CSV ë¶„ì„ ì™„ë£Œ!")
                            
                            # ê¸´ê¸‰ ìƒí™© ì²´í¬
                            emergency = st.session_state.chatbot.get_emergency_alert()
                            if emergency:
                                st.error("ğŸš¨ ê¸´ê¸‰ ìƒí™© ê°ì§€!")
        
        elif upload_method == "JSON íŒŒì¼":
            uploaded_file = st.file_uploader(
                "JSON íŒŒì¼ì„ ë“œë˜ê·¸í•˜ê±°ë‚˜ ì„ íƒí•˜ì„¸ìš”",
                type=['json'],
                help="ì›Œí„°íŒí”„ ì˜¨ë„ ë¶„ì„ JSON íŒŒì¼"
            )
            
            if uploaded_file and not st.session_state.data_loaded:
                if st.session_state.chatbot.load_json_data(uploaded_file):
                    st.session_state.data_loaded = True
                    st.success("âœ… JSON ë°ì´í„° ë¡œë“œ ì™„ë£Œ!")
                    
                    # ê¸´ê¸‰ ìƒí™© ì²´í¬
                    emergency = st.session_state.chatbot.get_emergency_alert()
                    if emergency:
                        st.error("ğŸš¨ ê¸´ê¸‰ ìƒí™© ê°ì§€!")
        
        else:  # ìƒ˜í”Œ ë°ì´í„°
            if st.button("ğŸ² ìƒ˜í”Œ ë°ì´í„° ìƒì„±") and not st.session_state.data_loaded:
                with st.spinner("ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì¤‘..."):
                    create_sample_data_for_chatbot()
                    st.session_state.data_loaded = True
                    st.success("âœ… ìƒ˜í”Œ ë°ì´í„° ìƒì„± ì™„ë£Œ!")
        
        # ë°ì´í„° ì •ë³´ í‘œì‹œ
        if st.session_state.data_loaded and st.session_state.chatbot.data:
            st.write("---")
            st.write("ğŸ“Š **ë¡œë“œëœ ë°ì´í„° ì •ë³´**")
            metadata = st.session_state.chatbot.data.get('metadata', {})
            st.write(f"ì´ ë°°ì¹˜: {metadata.get('total_batches', 'N/A')}ê°œ")
            st.write(f"ë°ì´í„° ì†ŒìŠ¤: {metadata.get('data_source', 'N/A')}")
            
            cache = st.session_state.chatbot.analysis_cache
            if cache:
                st.write(f"í‰ê·  ì˜¨ë„: {cache['avg_temperature']:.1f}Â°C")
                critical_count = cache['alert_counts']['ìœ„í—˜'] + cache['alert_counts']['ì£¼ì˜']
                st.write(f"ìœ„í—˜/ì£¼ì˜: {critical_count}ê°œ")
    
    # ë©”ì¸ ì˜ì—­
    if not st.session_state.data_loaded:
        display_upload_guide()
        return
    
    # ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
    st.header("ğŸ’¬ AI ë¶„ì„ ì±„íŒ…")
    
    # ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”
    if 'messages' not in st.session_state:
        st.session_state.messages = [
            {"role": "assistant", "content": "ì•ˆë…•í•˜ì„¸ìš”! ì›Œí„°íŒí”„ ì˜¨ë„ ë¶„ì„ ì „ë¬¸ AIì…ë‹ˆë‹¤. ë°ì´í„° ë¶„ì„ì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”! ğŸŒ¡ï¸"}
        ]
    
    # ì±„íŒ… ë©”ì‹œì§€ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # ì‚¬ìš©ì ì…ë ¥
    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”..."):
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # AI ì‘ë‹µ ìƒì„±
        with st.chat_message("assistant"):
            with st.spinner("ë¶„ì„ ì¤‘..."):
                response = st.session_state.chatbot.analyze_user_query(prompt)
                st.markdown(response)
                st.session_state.messages.append({"role": "assistant", "content": response})
    
    # í€µ ì•¡ì…˜ ë²„íŠ¼
    st.header("ğŸš€ ë¹ ë¥¸ ë¶„ì„")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ“Š ì „ì²´ í˜„í™©"):
            response = st.session_state.chatbot.get_overall_analysis()
            st.session_state.messages.append({"role": "user", "content": "ì „ì²´ í˜„í™© ë¶„ì„"})
            st.session_state.messages.append({"role": "assistant", "content": response})
            st.rerun()
    
    with col2:
        if st.button("âš ï¸ ìœ„í—˜ ë¶„ì„"):
            response = st.session_state.chatbot.get_risk_analysis()
            st.session_state.messages.append({"role": "user", "content": "ìœ„í—˜ ìš”ì†Œ ë¶„ì„"})
            st.session_state.messages.append({"role": "assistant", "content": response})
            st.rerun()
    
    with col3:
        if st.button("ğŸ”§ ì •ë¹„ ì¡°ì–¸"):
            response = st.session_state.chatbot.get_maintenance_advice()
            st.session_state.messages.append({"role": "user", "content": "ì •ë¹„ ê³„íš ì¡°ì–¸"})
            st.session_state.messages.append({"role": "assistant", "content": response})
            st.rerun()

if __name__ == "__main__":
    main()


##
## streamlit run chatbot_implementation.py
## 
